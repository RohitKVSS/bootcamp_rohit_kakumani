{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6afa43ab-6401-426a-8321-469f9afa6a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA counts:\n",
      " date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "Shape: (100, 6)\n",
      "         date     open     high       low   close     volume\n",
      "0  2025-04-01   83.890   85.280   81.8201   84.68   78980662\n",
      "1  2025-04-02   82.400   88.405   82.3000   87.45   96563137\n",
      "2  2025-04-03   81.250   85.680   81.0100   83.60   93878189\n",
      "3  2025-04-04   80.070   80.980   71.9303   74.01  147323190\n",
      "4  2025-04-07   66.650   81.800   66.1200   77.84  169083704\n",
      "..        ...      ...      ...       ...     ...        ...\n",
      "95 2025-08-18  175.270  177.900  171.3900  174.03   62656597\n",
      "96 2025-08-19  171.360  172.300  156.9000  157.75  137922722\n",
      "97 2025-08-20  152.300  156.460  142.3400  156.01  220336359\n",
      "98 2025-08-21  157.170  157.970  153.8100  156.18   94678639\n",
      "99 2025-08-22  155.315  163.200  151.7700  158.74  102099177\n",
      "\n",
      "[100 rows x 6 columns]\n",
      "Palantir stock data saved to data/raw/PLTR_raw.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"ALPHA_VANTAGE_KEY\")\n",
    "\n",
    "# Alpha Vantage endpoint for daily stock prices\n",
    "symbol = \"PLTR\"\n",
    "url = \"https://www.alphavantage.co/query\"\n",
    "params = {\n",
    "    \"function\": \"TIME_SERIES_DAILY\",\n",
    "    \"symbol\": symbol,\n",
    "    \"apikey\": api_key\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "time_series = data.get(\"Time Series (Daily)\", {})\n",
    "df = pd.DataFrame.from_dict(time_series, orient = \"index\")\n",
    "\n",
    "\n",
    "# Reset index, rename columns\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={\"index\": \"date\",\n",
    "                   \"1. open\": \"open\",\n",
    "                   \"2. high\": \"high\",\n",
    "                   \"3. low\": \"low\",\n",
    "                   \"4. close\": \"close\",\n",
    "                   \"5. volume\": \"volume\",}, inplace=True)\n",
    "\n",
    "# Parse dtypes\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "    df[col] = df[col].astype(float)\n",
    "df[\"volume\"] = df[\"volume\"].astype(int)\n",
    "\n",
    "\n",
    "# Validation\n",
    "required_columns = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "missing_cols = [c for c in required_columns if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "na_counts = df.isna().sum()\n",
    "print(\"NA counts:\\n\", na_counts)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Sort by date ascending\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "print(df)\n",
    "\n",
    "# Save raw CSV\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "df.to_csv(\"../data/raw/PLTR_raw.csv\", index=False)\n",
    "\n",
    "print(\"Palantir stock data saved to data/raw/PLTR_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28694ab-9fb1-45c3-83a7-785d3c3e9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kvssr\\anaconda3\\envs\\fe-course\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea04ab1b-e8e7-40a8-a34b-88b7fca0d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (503, 8)\n",
      "NA counts:\n",
      " Symbol                   0\n",
      "Security                 0\n",
      "GICS Sector              0\n",
      "GICS Sub-Industry        0\n",
      "Headquarters Location    0\n",
      "Date added               0\n",
      "CIK                      0\n",
      "Founded                  0\n",
      "dtype: int64\n",
      "✅ Saved to data/raw/sp500_companies.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "# Fetch page\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find table\n",
    "table = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "\n",
    "# Extract headers\n",
    "headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "# Extract rows\n",
    "rows = []\n",
    "for tr in table.find_all(\"tr\")[1:]:\n",
    "    cells = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "    if cells:  \n",
    "        rows.append(cells)\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Validation\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"NA counts:\\n\", df.isna().sum())\n",
    "\n",
    "if \"CIK\" in df.columns:\n",
    "    df[\"CIK\"] = pd.to_numeric(df[\"CIK\"], errors=\"coerce\")\n",
    "\n",
    "# Save raw CSV\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "df.to_csv(\"../data/raw/sp500_companies.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved to data/raw/sp500_companies.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40346c34-4e34-430c-8ee9-5d96cb71735e",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "1. **Alpha Vantage API**\n",
    "   - URL: `https://www.alphavantage.co/query`\n",
    "   - Params: \n",
    "     - `function = TIME_SERIES_DAILY_ADJUSTED`\n",
    "     - `symbol = PLTR`\n",
    "     - `outputsize = compact`\n",
    "     - `datatype = json`\n",
    "     - `apikey = <from .env>`\n",
    "\n",
    "2. **Wikipedia (S&P 500 companies)**\n",
    "   - URL: `https://en.wikipedia.org/wiki/List_of_S%26P_500_companies`\n",
    "   - Method: Scrape using `requests` + `BeautifulSoup`\n",
    "   - Target: Table with `id=\"constituents\"`\n",
    "\n",
    "---\n",
    "\n",
    "### Validation Logic\n",
    "- **Alpha Vantage**\n",
    "  - Ensure `\"Time Series (Daily)\"` exists in JSON\n",
    "  - Check required columns: `[date, open, high, low, close, adjusted_close, volume]`\n",
    "  - Validate dtypes:\n",
    "    - `date` → datetime\n",
    "    - price fields → float\n",
    "    - `volume` → int\n",
    "  - Print shape + NA counts\n",
    "\n",
    "- **Wikipedia Table**\n",
    "  - Ensure table with `id=\"constituents\"` is found\n",
    "  - Validate column headers (`Symbol`, `Security`, `GICS Sector`, etc.)\n",
    "  - Convert `CIK` to numeric\n",
    "  - Print shape + NA counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4180a4-7cb3-4f19-a3b7-91ff86d9fbc3",
   "metadata": {},
   "source": [
    "### Assumptions & Risks\n",
    "- **API Limits**: Alpha Vantage free tier allows only 5 requests per minute. Risk of `Note` responses if limit exceeded.  \n",
    "- **Data Completeness**: Alpha Vantage may not provide full history with `outputsize=compact`. Assumption: compact (100 days) is sufficient for this notebook.  \n",
    "- **Data Accuracy**: Wikipedia tables may not always be up-to-date. Assumption: Wikipedia list is reasonably current but could lag official S&P sources.  \n",
    "- **Schema Stability**: Both Alpha Vantage JSON keys and Wikipedia table structure are assumed to remain stable; changes may break parsing logic.  \n",
    "- **Missing Data**: Assumption that occasional missing values (`NaN`) can be filled or dropped without materially impacting analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d584090-7eca-44d2-87e8-3b05f4b7e114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
